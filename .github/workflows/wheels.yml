name: build-triton-cp38-aarch64
on:
  workflow_dispatch:
    inputs:
      jobs:
        description: Number of parallel cores
        required: false
        default: "96"

jobs:
  wheel:
    runs-on: self-hosted
    timeout-minutes: 600
    steps:
      - uses: actions/checkout@v4
        with:
          repository: triton-lang/triton
          fetch-depth: 0

      - name: Checkout tag v2.1.0
        run: |
          set -eux
          git fetch --tags --force
          git -c advice.detachedHead=false checkout "refs/tags/v2.1.0" || git checkout v2.1.0
          git submodule update --init --recursive
          git rev-parse --short HEAD

      - uses: actions/cache@v4
        with:
          path: .ccache
          key: ccache-${{ runner.os }}-${{ github.sha }}
          restore-keys: |
            ccache-${{ runner.os }}-

      - name: Install build deps + CUDA repo (Ubuntu 20.04 ARM/SBSA)
        run: |
          set -eux
          sudo apt-get update
          sudo apt-get install -y \
            build-essential cmake ninja-build ccache \
            python3.8 python3.8-dev python3.8-venv python3-pip \
            git curl pkg-config ca-certificates

          # Add NVIDIA CUDA SBSA repo for Ubuntu 20.04 (ARM64)
          curl -fsSL \
            https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/cuda-keyring_1.1-1_all.deb \
            -o cuda-keyring.deb
          sudo dpkg -i cuda-keyring.deb || true
          sudo apt-get update

          # Install a package that provides ptxas (11.4 matches JP5.x era; 11.x is fine for Triton v2.1)
          (sudo apt-get install -y cuda-toolkit-11-4) || \
          (sudo apt-get install -y cuda-compiler-11-4) || \
          (sudo apt-get install -y cuda-nvcc-11-4)

          # Prefer CUDA 11.4 if installed; otherwise fall back to whatever /usr/local/cuda points to
          if [ -x /usr/local/cuda-11.4/bin/ptxas ]; then
            echo "Found ptxas at /usr/local/cuda-11.4/bin/ptxas"
          elif [ -x /usr/local/cuda/bin/ptxas ]; then
            echo "Found ptxas at /usr/local/cuda/bin/ptxas"
          else
            echo "::error ::ptxas not found after installing CUDA packages."
            exit 1
          fi

      - name: Build cp38 wheel on host (no manylinux)
        env:
          J: ${{ inputs.jobs }}
        run: |
          set -euxo pipefail
          # heartbeat so the job stays chatty
          ( while true; do echo "::notice::build still running $(date -u)"; sleep 60; done ) & HB=$!

          # parallelism (default to all cores)
          if [ -z "${J:-}" ]; then J=$(nproc); fi
          LJ=$(( J/4 + 1 )); [ "$LJ" -lt 1 ] && LJ=1

          # ensure defaults so set -u won't choke
          : "${GITHUB_WORKSPACE:=$PWD}"
          : "${HOME:=$GITHUB_WORKSPACE}"

          # Point PATH/CUDA_HOME at the installed CUDA so Triton can find native ARM64 ptxas
          if [ -x /usr/local/cuda-11.4/bin/ptxas ]; then
            export CUDA_HOME=/usr/local/cuda-11.4
          else
            export CUDA_HOME=/usr/local/cuda
          fi
          export PATH="$CUDA_HOME/bin:$PATH"
          export TRITON_PTXAS_PATH="$CUDA_HOME/bin/ptxas"
          command -v ptxas && ptxas --version

          # isolate build tools from system Python
          python3.8 -m venv .pbuild
          . .pbuild/bin/activate

          # Ensure pip exists (venv should have it; bootstrap just in case)
          python -m pip --version || (curl -fsSL https://bootstrap.pypa.io/pip/3.8/get-pip.py -o get-pip.py && python get-pip.py)
          python -m pip install -U pip setuptools wheel

          # Speed-ups (ccache in workspace)
          mkdir -p .ccache
          export CCACHE_DIR="$PWD/.ccache"
          export CC="ccache gcc" CXX="ccache g++"
          export CFLAGS="-march=armv8-a" CXXFLAGS="-march=armv8-a"

          # Leaner LLVM inside Triton build
          export TRITON_CMAKE_FLAGS="
            -DCMAKE_BUILD_TYPE=Release
            -DCMAKE_C_COMPILER_LAUNCHER=ccache
            -DCMAKE_CXX_COMPILER_LAUNCHER=ccache
            -DLLVM_ENABLE_ASSERTIONS=OFF
            -DLLVM_ENABLE_PROJECTS=mlir;llvm;lld
            -DLLVM_TARGETS_TO_BUILD=AArch64;NVPTX
            -DLLVM_INCLUDE_TESTS=OFF
            -DLLVM_INCLUDE_EXAMPLES=OFF
            -DLLVM_OPTIMIZED_TABLEGEN=ON
          "

          # Parallel knobs
          export CMAKE_BUILD_PARALLEL_LEVEL="$J"
          export LLVM_PARALLEL_COMPILE_JOBS="$J"
          export LLVM_PARALLEL_LINK_JOBS="$LJ"
          export NINJAFLAGS="-v -j$J -l$J"

          # Build wheel (linux_aarch64)
          cd python
          python -m pip wheel --no-deps -w ../wheelhouse .
          ls -lh ../wheelhouse/*
          kill $HB || true

      - uses: actions/upload-artifact@v4
        with:
          name: triton-aarch64-cp38-ubuntu2004
          path: wheelhouse/*-linux_aarch64.whl
          retention-days: 30
          compression-level: 0
